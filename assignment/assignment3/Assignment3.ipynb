{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8afc3873",
   "metadata": {},
   "source": [
    "# Implement Backpropagation algorithm to train majority function with 3-bits. Use network of configuration 3x2x2x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628330ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Required Libaries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcd647",
   "metadata": {},
   "source": [
    "## Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f479b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe97f0",
   "metadata": {},
   "source": [
    "## Derivative of Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527ca186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcbf2c",
   "metadata": {},
   "source": [
    "## Creating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5815753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,0,0],[0,0,1],[0,1,1],[0,1,0],[1,0,0],[1,0,1],[1,1,0],[1,1,1]])\n",
    "t = np.array([[0],[0],[1],[0],[0],[1],[1],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ccc18c",
   "metadata": {},
   "source": [
    "## Setting Up Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a167a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce28bd",
   "metadata": {},
   "source": [
    "## Setting up Neural Network Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e78483",
   "metadata": {},
   "outputs": [],
   "source": [
    "ILNeurons, HLNeurons1,HLNeurons2, OLNeurons = 3,2,2,1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59968c97",
   "metadata": {},
   "source": [
    "## Weight and Bias Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43d8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh1 = np.random.uniform(size=(ILNeurons,HLNeurons1))\n",
    "bh1 =np.random.uniform(size=(1,HLNeurons1))\n",
    "\n",
    "wh2 = np.random.uniform(size=(HLNeurons1,HLNeurons2))\n",
    "bh2 =np.random.uniform(size=(1,HLNeurons2))\n",
    "\n",
    "wo = np.random.uniform(size=(HLNeurons2,OLNeurons))\n",
    "bo = np.random.uniform(size=(1,OLNeurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17407d06",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b74f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden Layer 1 weights: [3.3311879 1.8427214] [3.30723517 1.88264993] [3.30582667 1.88495384]\n",
      "Final hidden Layer 2 weights: [7.21834025 2.48352736] [3.17622517 1.56641908]\n",
      "Final hidden Layer 1 bias: [-5.04352362 -2.90221059]\n",
      "Final hidden Layer 2 bias: [-5.09232956 -1.94198313]\n",
      "Final output weights: [11.91501417] [2.85712987]\n",
      "Final output bias: [-4.92681678]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.01157858] [0.02272764] [0.99983127] [0.0227233] [0.022649] [0.99983069] [0.99983066] [0.99991943]\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # Forward Propagation\n",
    "    vh1 = np.dot(x,wh1)\n",
    "    vh1+=bh1\n",
    "    yh1 = sigmoid(vh1)\n",
    "    \n",
    "    vh2 = np.dot(yh1,wh2)\n",
    "    vh2+=bh2\n",
    "    yh2 = sigmoid(vh2)\n",
    "    \n",
    "    vo = np.dot(yh2,wo)\n",
    "    vo+=bo\n",
    "    yo = sigmoid(vo)\n",
    "    \n",
    "    # Back Propagation\n",
    "    error = t-yo\n",
    "    deltao = error+sigmoid_derivative(yo)\n",
    "    \n",
    "    hidden_err2 = deltao.dot(wo.T)\n",
    "    deltah2 = hidden_err2*sigmoid_derivative(yh2)\n",
    "    \n",
    "    hidden_err1 = deltah2.dot(wh2.T)\n",
    "    deltah1 = hidden_err1*sigmoid_derivative(yh1)\n",
    "    \n",
    "    # Udating the Weights and Bias\n",
    "    wo+=yh2.T.dot(deltao)*lr\n",
    "    bo+=np.sum(deltao,axis=0,keepdims=True)*lr\n",
    "    \n",
    "    wh2+=yh1.T.dot(deltah2)*lr\n",
    "    bh2+=np.sum(deltah2,axis=0,keepdims=True)*lr\n",
    "    \n",
    "    wh1+=x.T.dot(deltah1)*lr\n",
    "    bh1+=np.sum(deltah1,axis=0,keepdims=True)*lr\n",
    "    \n",
    "print(\"Final hidden Layer 1 weights: \",end='')\n",
    "print(*wh1)\n",
    "print(\"Final hidden Layer 2 weights: \",end='')\n",
    "print(*wh2)\n",
    "print(\"Final hidden Layer 1 bias: \",end='')\n",
    "print(*bh1)\n",
    "print(\"Final hidden Layer 2 bias: \",end='')\n",
    "print(*bh2)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*wo)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*bo)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*yo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
